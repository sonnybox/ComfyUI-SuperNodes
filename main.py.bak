import torch
import math
import torch.nn.functional as F

# Helper function to generate a feather mask
def generate_feather_mask(shape, overlap, radius, device):
    """
    Generates a weight mask with a linear fade-out at the edges.
    shape: (H, W, C) or (H, W)
    radius: pixels to fade
    """
    h, w = shape[:2]
    mask = torch.ones((h, w), dtype=torch.float32, device=device)
    
    if radius <= 0:
        return mask

    # Clamp radius to half the size to prevent negative indices
    radius = min(radius, h // 2, w // 2)

    # Create ramps
    ramp = torch.linspace(0, 1, radius, device=device)
    
    # Top edge
    mask[:radius, :] *= ramp.unsqueeze(1)
    # Bottom edge
    mask[-radius:, :] *= ramp.flip(0).unsqueeze(1)
    # Left edge
    mask[:, :radius] *= ramp.unsqueeze(0)
    # Right edge
    mask[:, -radius:] *= ramp.flip(0).unsqueeze(0)
    
    return mask

class CreateTiles:
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "image": ("IMAGE",),
                "rows": ("INT", {"default": 2, "min": 1, "max": 64, "step": 1}),
                "cols": ("INT", {"default": 2, "min": 1, "max": 64, "step": 1}),
                "overlap": ("INT", {"default": 32, "min": 0, "max": 512, "step": 4}),
            }
        }

    RETURN_TYPES = ("IMAGE", "STITCH_INFO")
    RETURN_NAMES = ("tiles", "stitch_info")
    FUNCTION = "execute"
    CATEGORY = "SuperNodes"
    
    def execute(self, image, rows, cols, overlap):
        # image shape: [B, H, W, C]
        batch_size, h, w, c = image.shape
        
        # Calculate expected tile dimensions to ensure they are all identical
        # We divide the image into a grid, then add overlap
        base_h = h // rows
        base_w = w // cols
        
        tile_h = base_h + overlap
        tile_w = base_w + overlap
        
        # Ensure we don't exceed image bounds in the tile definition
        tile_h = min(tile_h, h)
        tile_w = min(tile_w, w)

        all_tiles = []
        stitch_data = []

        # Iterate over batch
        for b in range(batch_size):
            img = image[b] # [H, W, C]
            
            tile_coords = []
            
            for r in range(rows):
                for c_idx in range(cols):
                    # Calculate ideal center based top-left
                    # We want to distribute the overlap evenly, but ensure fixed size
                    
                    # Naive grid start
                    y = r * base_h
                    x = c_idx * base_w
                    
                    # Adjust for overlap (shifting back by half overlap to center the seam)
                    # We treat the first row/col as anchored to 0
                    if r > 0: y -= overlap // 2
                    if c_idx > 0: x -= overlap // 2
                    
                    # Constraints to keep tile size constant
                    y_start = max(0, min(y, h - tile_h))
                    x_start = max(0, min(x, w - tile_w))
                    
                    y_end = y_start + tile_h
                    x_end = x_start + tile_w
                    
                    # Crop
                    crop = img[y_start:y_end, x_start:x_end, :]
                    all_tiles.append(crop)
                    
                    # Store absolute coordinates for reconstruction
                    tile_coords.append({
                        "b_index": b,
                        "row_idx": r,
                        "col_idx": c_idx,
                        "y": y_start,
                        "x": x_start,
                        "h": tile_h,
                        "w": tile_w
                    })

        # Stack all tiles into a new batch [Batch * Rows * Cols, TileH, TileW, C]
        output_tiles = torch.stack(all_tiles)
        
        # Metadata object
        stitch_info = {
            "original_height": h,
            "original_width": w,
            "original_batch_size": batch_size,
            "rows": rows,
            "cols": cols,
            "overlap": overlap,
            "tiles": tile_coords
        }

        return (output_tiles, stitch_info)

class StitchTiles:
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "tiles": ("IMAGE",),
                "stitch_info": ("STITCH_INFO",),
                "blend_mode": (["None", "Linear", "Feather"],),
                "blend_radius": ("INT", {"default": 32, "min": 1, "max": 256, "step": 1}),
            }
        }

    RETURN_TYPES = ("IMAGE",)
    FUNCTION = "execute"
    CATEGORY = "SuperNodes"

    def execute(self, tiles, stitch_info, blend_mode, blend_radius):
        # tiles shape: [TotalTiles, TH, TW, C]
        if tiles.shape[0] != len(stitch_info["tiles"]):
            raise ValueError(f"Mismatch: Info expects {len(stitch_info['tiles'])} tiles, but got {tiles.shape[0]}. Did you change batch size in between?")
            
        device = tiles.device
        
        # Calculate Scale Factor
        # Compare current tile width vs original tile width stored in metadata
        current_tile_h, current_tile_w = tiles.shape[1], tiles.shape[2]
        orig_tile_h = stitch_info["tiles"][0]["h"]
        orig_tile_w = stitch_info["tiles"][0]["w"]
        
        scale_h = current_tile_h / orig_tile_h
        scale_w = current_tile_w / orig_tile_w
        
        # Calculate New Output Dimensions
        final_h = round(stitch_info["original_height"] * scale_h)
        final_w = round(stitch_info["original_width"] * scale_w)
        original_batch_size = stitch_info["original_batch_size"]
        channels = tiles.shape[3]

        # Prepare Output Canvas: [B, H, W, C]
        # We need an accumulator for colors and an accumulator for weights (alpha)
        out_image = torch.zeros((original_batch_size, final_h, final_w, channels), device=device)
        out_weights = torch.zeros((original_batch_size, final_h, final_w, 1), device=device)
        
        # Generate Mask based on blend mode
        # The mask is applied to the tile before adding to canvas
        weight_mask = torch.ones((current_tile_h, current_tile_w), device=device)
        
        if blend_mode == "Feather":
            # Apply feathering to the mask
            # Adjust radius if upscale happened
            effective_radius = int(blend_radius * (scale_w + scale_h) / 2)
            weight_mask = generate_feather_mask((current_tile_h, current_tile_w), stitch_info["overlap"], effective_radius, device)
        
        weight_mask = weight_mask.unsqueeze(-1) # [TH, TW, 1]

        # Reconstruction Loop
        for i, tile_meta in enumerate(stitch_info["tiles"]):
            b_idx = tile_meta["b_index"]
            
            # Retrieve the tile image
            tile_img = tiles[i] # [TH, TW, C]
            
            # Calculate new coordinates
            y_start = round(tile_meta["y"] * scale_h)
            x_start = round(tile_meta["x"] * scale_w)
            
            y_end = y_start + current_tile_h
            x_end = x_start + current_tile_w
            
            # Handle rounding edge cases where it might exceed canvas by 1px
            y_end = min(y_end, final_h)
            x_end = min(x_end, final_w)
            
            # Crop tile if it goes out of bounds (due to rounding)
            h_actual = y_end - y_start
            w_actual = x_end - x_start
            
            tile_crop = tile_img[:h_actual, :w_actual, :]
            mask_crop = weight_mask[:h_actual, :w_actual, :]
            
            if blend_mode == "None":
                # Direct overwrite (last tile wins)
                out_image[b_idx, y_start:y_end, x_start:x_end, :] = tile_crop
                out_weights[b_idx, y_start:y_end, x_start:x_end, :] = 1.0
            else:
                # Accumulate
                out_image[b_idx, y_start:y_end, x_start:x_end, :] += tile_crop * mask_crop
                out_weights[b_idx, y_start:y_end, x_start:x_end, :] += mask_crop

        # Normalize
        # Avoid division by zero
        out_weights[out_weights == 0] = 1.0
        final_image = out_image / out_weights
        
        return (final_image,)
